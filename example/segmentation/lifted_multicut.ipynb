{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lifted Multicut\n",
    "\n",
    "Use the `elf.segmentation` module for boundary **and prior** based lifted multicut segmentation: [Leveraging Domain Knowledge to Improve Microscopy Image Segmentation With Lifted Multicuts](https://doi.org/10.3389/fcomp.2019.00006).\n",
    "You can obtain the data from [here](https://oc.embl.de/index.php/s/kzdYaPlmr2NWCni).\n",
    "\n",
    "The segmentation approach works as follows:\n",
    "1. Predict pixel-wise boundary (or affinity) map. Here, we use pre-computed results from ilastik.\n",
    "2. Compute a watershed over-segmentation based on the boundary maps.\n",
    "3. Compute the region adjacency graph defined by the watershed over-segmentation.\n",
    "4. Compute weights for the edges of this graph by accumulating the boundary (or affinity) map over the edge pixels.\n",
    "5. Map the biological priors to watershed segments and use this to insert lifted edges.\n",
    "6. Partition the graph based on the local and lifted edge weights via Lifted Multicut and project the result back to the pixel level.\n",
    "\n",
    "Here, we use the prior information that axonic and dendritic compartments should belong to seperate \n",
    "neurites in a constrained volume of mammalian neural tissue. We use probability maps trained to identify vesicles and dendritic shafts in order to attribute axon / dendrite labels to superpixels.\n",
    "\n",
    "Please note that the membrane probability maps used here do not correspond to the ones in the paper yet and are much worse than the ones we have used in there. Consequently, also the end result looks much worse than in the paper. I will try to update this data soon, still this example gives a good over-view in the steps involved to apply lifted multicut segmentation to your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui qt5 \n",
    "import numpy as np\n",
    "\n",
    "# import napari for data visualisation\n",
    "import napari\n",
    "\n",
    "# import the segmentation functionality from elf\n",
    "import elf.segmentation.multicut as mc\n",
    "import elf.segmentation.lifted_multicut as lmc\n",
    "import elf.segmentation.features as feats\n",
    "import elf.segmentation.watershed as ws\n",
    "\n",
    "# import the open_file function from elf, which supports opening files\n",
    "# in hdf5, zarr, n5 or knossos file format\n",
    "from elf.io import open_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "# you can download the example data from here:\n",
    "# https://oc.embl.de/index.php/s/kzdYaPlmr2NWCni\n",
    "data_path = '/home/pape/Work/data/mmwc/knott_data.h5'  # adjust this path\n",
    "with open_file(data_path, 'r') as f:\n",
    "    # load the raw data\n",
    "    raw = f['raw'][:]\n",
    "    # load the membrane probability maps\n",
    "    pmap = f['probs/membranes'][:]\n",
    "    # load the dendrite and vesicle probability maps\n",
    "    den_map = f['probs/dendrites'][:]\n",
    "    ves_map = f['probs/vesicles'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the input data with napari\n",
    "# TODO switch to new napari api\n",
    "# napari.view_image(raw, name='raw')\n",
    "# napari.view_image(pmap, name='membrane-probabilities')\n",
    "# napari.view_image(den_map, name='dendrite-probabilities')\n",
    "# napari.view_image(ves_map, name='vesicle-probabilities')\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(raw, name='raw')\n",
    "viewer.add_image(pmap, name='membranes')\n",
    "viewer.add_image(den_map, name='dendrites')\n",
    "viewer.add_image(ves_map, name='vesicles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the watershed\n",
    "print(\"3D watershed is running, this will take a while ...\")\n",
    "watershed = ws.distance_transform_watershed(pmap, threshold=.6, \n",
    "                                            sigma_seeds=2.)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the watershed result\n",
    "# TODO switch to new napari syntax\n",
    "# napari.view_image(raw, name='raw')\n",
    "# napari.add_labels(watershed, name='watershed')\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(raw, name='raw')\n",
    "viewer.add_labels(watershed, name='watershed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the region adjacency graph\n",
    "rag = feats.compute_rag(watershed)\n",
    "\n",
    "# compute the edge costs\n",
    "features = feats.compute_boundary_mean_and_length(rag, pmap)\n",
    "costs, sizes = features[:, 0], features[:, 1]\n",
    "\n",
    "# transform the edge costs from [0, 1] to  [-inf, inf], which is\n",
    "# necessary for the multicut. This is done by intepreting the values\n",
    "# as probabilities for an edge being 'true' and then taking the negative log-likelihood.\n",
    "# in addition, we weight the costs by the size of the corresponding edge\n",
    "\n",
    "# we choose a boundary bias smaller than 0.5 in order to\n",
    "# decrease the degree of over segmentation\n",
    "boundary_bias = .45\n",
    "\n",
    "costs = mc.transform_probabilities_to_costs(costs, edge_sizes=sizes,\n",
    "                                            beta=boundary_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute lifted multicut features from vesicle and dendrite pmaps\n",
    "input_maps = [den_map, ves_map]\n",
    "assignment_threshold = .8\n",
    "lifted_uvs, lifted_costs = feats.lifted_problem_from_probabilities(rag, watershed,\n",
    "                                                                   input_maps, assginment_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Multicut and Lifted Multicut solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solve the multicut for a baseline\n",
    "node_labels = mc.multicut_kernighan_lin(rag, costs)\n",
    "# map the results back to pixels to obtain the final segmentation\n",
    "segmentation = feats.project_node_labels_to_pixels(rag, node_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solve the full lifted problem using the kernighan lin approximation introduced in\n",
    "# http://openaccess.thecvf.com/content_iccv_2015/html/Keuper_Efficient_Decomposition_of_ICCV_2015_paper.html\n",
    "node_labels = lmc.lifted_multicut_kernighan_lin(rag, costs,\n",
    "                                                lifted_uvs, lifted_costs)\n",
    "lifted_segmentation = feats.project_node_labels_to_pixes(rag, node_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the multicut and lifted multicut result\n",
    "\n",
    "# TODO switch to new napari syntax\n",
    "# napari.view_image(raw, name='raw')\n",
    "# napari.add_labels(segmentation, name='multicut-segmentation')\n",
    "# napari.add_labels(lifted_segmentation, name='lifted-multicut-segmentation')\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(raw, name='raw')\n",
    "viewer.add_labels(segmentation, name='multicut')\n",
    "viewer.add_labels(lifted_segmentation, name='lifted-multicut')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
