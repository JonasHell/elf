{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multicut\n",
    "\n",
    "Use the `elf.segmentation` module for boundary based multicut segmentation: [Multicut brings automated neurite segmentation closer to human performance](https://www.nature.com/articles/nmeth.4151). We use data from the [ISBI 2012 EM Segmentation challenge](http://brainiac2.mit.edu/isbi_challenge/home) and [The Mutex Watershed: Efficent, Parameter-Free Image Partitionong](http://openaccess.thecvf.com/content_ECCV_2018/html/Steffen_Wolf_The_Mutex_Watershed_ECCV_2018_paper.html).\n",
    "You can obtain the example data [here](https://hcicloud.iwr.uni-heidelberg.de/index.php/s/6LuE7nxBN3EFRtL).\n",
    "\n",
    "The boundary based segmentation approach works as follows:\n",
    "1. Predict pixel-wise affinity (or boundary) map. Here, we use pre-computed results for this step.\n",
    "2. Compute a watershed over-segmentation based on the affinity maps.\n",
    "3. Compute the region adjacency graph defined by the watershed over-segmentation.\n",
    "4. Compute weights for the edges of this graph by accumulating the affinity (or boundary) map over the edge pixels.\n",
    "5. Partition the graph based on the edge weights via Multicut and project the result back to the pixel level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui qt5 \n",
    "import numpy as np\n",
    "\n",
    "# import napari for data visualisation\n",
    "import napari\n",
    "\n",
    "# import the segmentation functionality from elf\n",
    "import elf.segmentation.multicut as mc\n",
    "import elf.segmentation.features as feats\n",
    "import elf.segmentation.watershed as ws\n",
    "\n",
    "# import the open_file function from elf, which supports opening files\n",
    "# in hdf5, zarr, n5 or knossos file format\n",
    "from elf.io import open_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "# you can download the example data from here:\n",
    "# https://hcicloud.iwr.uni-heidelberg.de/index.php/s/6LuE7nxBN3EFRtL\n",
    "data_path = '/home/pape/Work/data/isbi/isbi_test_volume.h5'  # adjust this path\n",
    "with open_file(data_path, 'r') as f:\n",
    "    # load the raw data\n",
    "    raw = f['raw'][:]\n",
    "    # load the affinities, we only need the first 3 channels\n",
    "    affs = f['affinities'][:3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the raw data and the affinity maps with napari\n",
    "# TODO switch to new napari syntax\n",
    "# napari.view_image(raw, name='raw')\n",
    "# napari.view_image(affs, name='affinities')\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(raw, name='raw')\n",
    "viewer.add_image(affs, name='affinities')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the Multicut problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute watershed over-segmentation based on the affinity maps\n",
    "\n",
    "# first, we have to make a single channel input map for the watershed,\n",
    "# which we obtain by averaging the afifnities\n",
    "boundary_input = np.mean(affs, axis=0)\n",
    "\n",
    "# next, we run the distance transform watershed.\n",
    "# the data is very anisotropic, so we apply the watershed in 2d\n",
    "# and stack the watershed results along z, with the appropriate id offset\n",
    "watershed = np.zeros_like(boundary_input, dtype='uint64')\n",
    "offset = 0\n",
    "for z in range(watershed.shape[0]):\n",
    "    # the threshold parameter determines at which value the input map is thresholded before applying\n",
    "    # the distance transform.\n",
    "    # the parameter sigma_seeds determines how strong the seed map is smoothed before seeds are\n",
    "    # computed via local minima. This controls the degree of over-segmentation\n",
    "    wsz, max_id = ws.distance_transform_watershed(boundary_input[z], threshold=.25, sigma_seeds=2.)\n",
    "    wsz += offset\n",
    "    offset += max_id\n",
    "    watershed[z] = wsz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the watershed result\n",
    "# TODO switch to new napari syntax\n",
    "# napari.view_image(raw, name='raw')\n",
    "# napari.add_labels(watershed, name='watershed')\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(raw, name='raw')\n",
    "viewer.add_labels(watershed, name='watershed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the region adjacency graph\n",
    "rag = feats.compute_rag(watershed)\n",
    "\n",
    "# compute the edge costs\n",
    "# the offsets encode the pixel transition encoded by the \n",
    "# individual affinity channels. Here, we only have nearest neighbor transitions\n",
    "offsets = [[-1, 0, 0], [0, -1, 0], [0, 0, -1]]\n",
    "costs = feats.compute_affinity_features(rag, affs, offsets)[:, 0]\n",
    "\n",
    "# transform the edge costs from [0, 1] to  [-inf, inf], which is\n",
    "# necessary for the multicut. This is done by intepreting the values\n",
    "# as probabilities for an edge being 'true' and then taking the negative log-likelihood.\n",
    "# in addition, we weight the costs by the size of the corresponding edge\n",
    "edge_sizes = feats.compute_boundary_mean_and_length(rag, boundary_input)[:, 1]\n",
    "costs = mc.transform_probabilities_to_costs(costs, edge_sizes=edge_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve the Multicut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the multicut partitioning, here, we use the kernighan lin \n",
    "# heuristics to solve the problem, introduced in\n",
    "# http://xilinx.asia/_hdl/4/eda.ee.ucla.edu/EE201A-04Spring/kl.pdf\n",
    "node_labels = mc.multicut_kernighan_lin(rag, costs)\n",
    "\n",
    "# map the results back to pixels to obtain the final segmentation\n",
    "segmentation = feats.project_node_labels_to_pixels(rag, node_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the segmentation result\n",
    "# TODO switch to new napari syntax\n",
    "# napari.view_image(raw, name='raw')\n",
    "# napari.add_labels(segmentation, name='multicut-segmentation')\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(raw, name='raw')\n",
    "viewer.add_labels(segmentation, name='multicut')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
