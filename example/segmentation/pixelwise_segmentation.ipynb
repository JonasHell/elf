{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pixelwise Segmentation\n",
    "\n",
    "Use the `elf.segmentation` module for feature based instance segmentation from pixels.\n",
    "Note that this example is educational and there are easier and better performing method for the image used here. These segmentation methods are very suitable for pixel embeddings learned with neural networks, e.g. with methods like [Semantic Instance Segmentation with a Discriminateive Loss Function](https://arxiv.org/abs/1708.02551)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image and Features\n",
    "\n",
    "Load the relevant libraries. Then load an image from the skimage examples and compute per pixel features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui qt5\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# import napari for data visualisation\n",
    "import napari\n",
    "\n",
    "# import vigra to compute per pixel features\n",
    "import vigra\n",
    "\n",
    "# elf segmentation functionality we need for the problem setup\n",
    "import elf.segmentation.features as feats\n",
    "from elf.segmentation.utils import normalize_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the coins example image\n",
    "from skimage.data import coins\n",
    "image = coins()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use blurring and texture filters from vigra.filters computed for different scales to obain pixel features.\n",
    "# Note that it's certainly possible to compute better features for the segmentation problem at hand.\n",
    "# But for our purposes, these features are good enough.\n",
    "im_normalized = normalize_input(image)\n",
    "\n",
    "scales = [4., 8., 12.]\n",
    "image_features = [im_normalized[None]]  # use the normal image as \n",
    "for scale in scales:\n",
    "    image_features.append(normalize_input(vigra.filters.gaussianSmoothing(im_normalized, scale))[None])\n",
    "    feats1 = vigra.filters.hessianOfGaussianEigenvalues(im_normalized, scale)\n",
    "    image_features.append(normalize_input(feats1[..., 0])[None])\n",
    "    image_features.append(normalize_input(feats1[..., 1])[None])\n",
    "    feats2 = vigra.filters.structureTensorEigenvalues(im_normalized, scale, 1.5 * scale)\n",
    "    image_features.append(normalize_input(feats2[..., 0])[None])\n",
    "    image_features.append(normalize_input(feats2[..., 1])[None])\n",
    "\n",
    "image_features = np.concatenate(image_features, axis=0)\n",
    "print(\"Feature shape:\")\n",
    "print(image_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the image and the features with napari\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(im_normalized)\n",
    "viewer.add_image(image_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation Problem\n",
    "\n",
    "Set up a graph segmentation problem based on the image and features with elf functionality.\n",
    "To this end, we construct a grid graph and compute edge features for the inter pixel edges in this graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute a grid graph for the image\n",
    "shape = image.shape\n",
    "grid_graph = feats.compute_grid_graph(shape)\n",
    "\n",
    "# compute the edge features\n",
    "# elf supports three different distance metrics to compute edge features\n",
    "# from the image features:\n",
    "# - 'l1': the l1 distance\n",
    "# - 'l2': the l2 distance\n",
    "# - 'cosine': the cosine distance (= 1. - cosine similarity)\n",
    "# here, we use the l2 distance\n",
    "distance_type = 'l2'\n",
    "\n",
    "# 'compute_grid-graph-image_features' returns both the edges (=list of node ids connected by the edge)\n",
    "# and the edge weights. Here, the edges are the same as grid_graph.uvIds()\n",
    "edges, edge_weights = feats.compute_grid_graph_image_features(grid_graph, image_features, distance_type)\n",
    "\n",
    "# we normalize the edge weigths to the range [0, 1]\n",
    "edge_weights = normalize_input(edge_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple post-processing to ensure the background label is '0',\n",
    "# filter small segments with a size of below 100 pixels\n",
    "# and ensure that the segmentation ids are consecutive\n",
    "def postprocess_segmentation(seg, shape, min_size=100):\n",
    "    if seg.ndim == 1:\n",
    "        seg = seg.reshape(shape)\n",
    "\n",
    "    ids, sizes = np.unique(seg, return_counts=True)\n",
    "    bg_label = ids[np.argmax(sizes)]\n",
    "\n",
    "    if bg_label != 0:\n",
    "        if 0 in seg:\n",
    "            seg[seg == 0] = seg.max() + 1\n",
    "        seg[seg == bg_label] = 0\n",
    "    \n",
    "    filter_ids = ids[sizes < min_size]\n",
    "    seg[np.isin(seg, filter_ids)] = 0\n",
    "    \n",
    "    vigra.analysis.relabelConsecutive(seg, out=seg, start_label=1, keep_zeros=True)\n",
    "    return seg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multicut\n",
    "\n",
    "As the first segmentation method, we use Multicut segmentation, based on the grid graph and the edge weights we have just computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the elf multicut funtionality\n",
    "import elf.segmentation.multicut as mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to apply multicut segmentation, we need to map the edge weights from their initial value range [0, 1]\n",
    "# to [-inf, inf]; where positive values represent attractive edges and negative values represent repulsive edges.\n",
    "\n",
    "# When computing these \"costs\" for the multicut, we can set the threshold for when an edge is counted\n",
    "# as repulsive with the so called boundary bias, or beta, parameter.\n",
    "# For values smaller than 0.5 the multicut segmentation will under-segment more,\n",
    "# for values larger than 0.4 it will over-segment more. \n",
    "beta = .75\n",
    "costs = mc.compute_edge_costs(edge_weights, beta=beta)\n",
    "print(\"Mapped edge weights in range\", edge_weights.min(), edge_weights.max(), \"to multicut costs in range\", costs.min(), costs.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the multicut segmentation\n",
    "t = time.time()\n",
    "mc_seg = mc.multicut_kernighan_lin(grid_graph, costs)\n",
    "print(\"Computing the segmentation with multicut took\", time.time() - t, \"s\")\n",
    "mc_seg = postprocess_segmentation(mc_seg, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the multicut segmentation\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(image)\n",
    "viewer.add_labels(mc_seg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long-range Segmentation Problem\n",
    "\n",
    "For now, we have only taken \"local\" information into account for the segmentation problem.\n",
    "More specifically, we have only solved the Multicut with edges derived from nearest neighbor pixel transitions.\n",
    "Next, we will use two algorithms, Mutex Watershed and Lifted Multicut, that can take long range edges into account. This has the advantage that feature differences are often more pronounced along larger distances, thus yielding much better information with respect to label transition.\n",
    "Here, we extract this information by defining a \"pixel offset pattern\" and comparing the pixel features for these offsets. For details about this segmentation approach check out [The Mutex Watershed: Efficient, Parameter-Free Image Partitioning](https://openaccess.thecvf.com/content_ECCV_2018/html/Steffen_Wolf_The_Mutex_Watershed_ECCV_2018_paper.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here, we define the following offset pattern:\n",
    "# straight and diagonal transitions at a radius of 3, 9 and 27 pixels\n",
    "# note that the offsets [-1, 0] and [0, -1] would correspond to the edges of the grid graph\n",
    "offsets = [\n",
    "    [-3, 0], [0, -3], [-3, 3], [3, 3],\n",
    "    [-9, 0], [0, -9], [-9, 9], [9, 9],\n",
    "    [-27, 0], [0, -27], [-27, 27], [27, 27]\n",
    "]\n",
    "\n",
    "# we have significantly more long range than normal edges.\n",
    "# hence, we subsample the offsets, for which actual long range edges will be computed by setting a stride factor\n",
    "strides = [2, 2]\n",
    "\n",
    "distance_type = 'l2'  # we again use l2 distance\n",
    "lr_edges, lr_edge_weights = feats.compute_grid_graph_image_features(grid_graph, image_features, distance_type,\n",
    "                                                                    offsets=offsets, strides=strides,\n",
    "                                                                    randomize_strides=False)\n",
    "lr_edge_weights = normalize_input(lr_edge_weights)\n",
    "print(\"Have computed\", len(lr_edges), \"long range edges, compared to\", len(edges), \"normal edges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutex Watershed\n",
    "\n",
    "We use the Mutex Watershed to segment the image. This algorithm functions similar to (Lifted) Multicut, but is greedy and hence much faster. Despite its greedy nature, for many problems the solutions are of similar quality than Multicut segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elf mutex watershed functionality\n",
    "import elf.segmentation.mutex_watershed as mws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "mws_seg = mws.mutex_watershed_clustering(edges, lr_edges, edge_weights, lr_edge_weights)\n",
    "print(\"Computing the segmentation with mutex watershed took\", time.time() - t, \"s\")\n",
    "mws_seg = postprocess_segmentation(mws_seg, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(image)\n",
    "viewer.add_labels(mws_seg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lifted Multicut\n",
    "\n",
    "Finally, we use Lifted Multicut segmentation. The Lifted Multicut is an extension to the Multicut, which can incorporate long range edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elf lifted multicut functionality\n",
    "import elf.segmentation.lifted_multicut as lmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the lifted multicut, we again need to transform the edge weights in [0, 1] to costs in [-inf, inf]\n",
    "beta = .75  # we again use a boundary bias of 0.75\n",
    "lifted_costs = mc.compute_edge_costs(lr_edge_weights, beta=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "lmc_seg = lmc.lifted_multicut_kernighan_lin(grid_graph, costs, lr_edges, lifted_costs)\n",
    "print(\"Computing the segmentation with lifted multicut took\", time.time() - t, \"s\")\n",
    "lmc_seg = postprocess_segmentation(lmc_seg, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(image)\n",
    "viewer.add_labels(lmc_seg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the segmentations\n",
    "\n",
    "We can now compare the three different segmentation. Note that the comparison is not quite fair here, because we have used the beta parameter to bias the segmentation to more over-segmentation for Multicut and Lifted Multicut while applying the Mutex Watershed to unbiased edge weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(image)\n",
    "viewer.add_labels(mc_seg)\n",
    "viewer.add_labels(mws_seg)\n",
    "viewer.add_labels(lmc_seg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
