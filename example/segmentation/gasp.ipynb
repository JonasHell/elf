{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GASP (Generalized Algorithm for Signed Graph Partitioning)\n",
    "\n",
    "Use the `elf.segmentation` module for boundary based segmentation with the GASP algorithm: [A Generalized Framework for Agglomerative Clustering of Signed Graphs applied to Instance Segmentation](https://arxiv.org/abs/1906.11713).\n",
    "Here we use some example data taken from the [ISBI 2012 EM Segmentation challenge](http://brainiac2.mit.edu/isbi_challenge/home).\n",
    "You can obtain this data [here](https://hcicloud.iwr.uni-heidelberg.de/index.php/s/6LuE7nxBN3EFRtL).\n",
    "\n",
    "GASP is a theoretical framework that generalizes\n",
    "simple and fast algorithms for hierarchical agglomerative\n",
    "clustering to weighted graphs with both attractive and repulsive interactions between the nodes.\n",
    "\n",
    "GASP can be used to cluster a weighted graph or can operate directly on pixel affinity maps. In the latter case, it produces a segmentation by partitioning the grid graph, taking into account long range pixel connections.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# import napari for data visualisation\n",
    "import napari\n",
    "\n",
    "# Import function to download the example data\n",
    "from elf.segmentation.utils import load_mutex_watershed_problem\n",
    "\n",
    "# import the segmentation functionality from elf\n",
    "from elf.segmentation import GaspFromAffinities\n",
    "from elf.segmentation import run_GASP\n",
    "\n",
    "# Import an utility function from nifty that we will need to generate a toy graph:\n",
    "from nifty.graph import UndirectedGraph\n",
    "\n",
    "# import the open_file function from elf, which supports opening files\n",
    "# in hdf5, zarr, n5 or knossos file format\n",
    "from elf.io import open_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download some example data and affinities:\n",
    "prefix = \"isbi-data-\"\n",
    "data_path = f\"{prefix}test.h5\"\n",
    "affs, offsets = load_mutex_watershed_problem(prefix=prefix)\n",
    "affs = 1. - affs\n",
    "with open_file(data_path, 'r') as f:\n",
    "    # load the raw data in addition\n",
    "    raw = f['raw'][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment an image using GASP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first need to decide which linkage criteria to use and whether\n",
    "# to use cannot-link constraints in the agglomeration. The\n",
    "# avbailable linkage criteria are:\n",
    "#     - `mean`, `average`, `avg` (average hierarchical clustering)\n",
    "#     - `max`, `single_linkage` (single hierarchical clustering)\n",
    "#     - `min`, `complete_linkage` (complete hierarchical clustering)\n",
    "#     - `mutex_watershed`, `abs_max` (mutex watershed algorithm)\n",
    "#     - `sum` (GAEC algorithm)\n",
    "\n",
    "# Here, as an example, we use average hierarchical clustering without\n",
    "# cannot-link constraints:\n",
    "run_GASP_kwargs = {'linkage_criteria': 'average',\n",
    "                   'add_cannot_link_constraints': False}\n",
    "\n",
    "# Run the algorithm:\n",
    "gasp_instance = GaspFromAffinities(offsets,\n",
    "                                   run_GASP_kwargs=run_GASP_kwargs)\n",
    "# To speed-up computations, here we use only part of the example data:\n",
    "segmentation, runtime = gasp_instance(affs[:,:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'gasp-avg-segmentation' at 0x7fe820e23850>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the result:\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(raw[:10], name='raw')\n",
    "viewer.add_image(affs[:,:10], name='affinities')\n",
    "viewer.add_labels(segmentation, name='gasp-avg-segmentation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option to use a superpixel generator\n",
    "Instead of segmenting an image starting from the pixel grid-graph, we can also first run an algorithm to generate superpixels and then use GASP on the generated graph.\n",
    "\n",
    "Here, as example, we will use a distance transform watershed algorithm to generate superpixels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from elf.segmentation.watershed import WatershedOnDistanceTransformFromAffinities\n",
    "\n",
    "# Here we define the superpixel generator.\n",
    "# You can also define your own generator. It should expect affinities and it should return a segmentation as output.\n",
    "superpixel_gen = WatershedOnDistanceTransformFromAffinities(offsets,\n",
    "                                                            threshold=0.4,\n",
    "                                                            sigma_seeds=0.1,\n",
    "                                                            min_size=20,\n",
    "                                                            stacked_2d=True,\n",
    "                                                            used_offsets=[1, 2],\n",
    "                                                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define another GASP instance, this time adding the superpixel generator:\n",
    "sp_gasp_instance = GaspFromAffinities(offsets,\n",
    "                                      superpixel_generator=superpixel_gen,\n",
    "                                      run_GASP_kwargs=run_GASP_kwargs)\n",
    "gasp_segmentation_sp, runtime_sp = sp_gasp_instance(affs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'gasp-segmentation-sp' at 0x7fe82044d280>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For visualization, let's compute again the generated superpixels and save them into\n",
    "# an array:\n",
    "superpixel_segm = superpixel_gen(affs)\n",
    "\n",
    "# Visualize the new segmentation in the viewer:\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(raw, name='raw')\n",
    "viewer.add_image(affs, name='affinities')\n",
    "viewer.add_labels(superpixel_segm, name='superpixels-segmentation')\n",
    "viewer.add_labels(gasp_segmentation_sp, name='gasp-segmentation-sp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering a weighted graph using GASP\n",
    "\n",
    "GASP can also be used to cluster a generic graph with both positive and negative weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# First, we generate a toy undirected graph with signed weights:\n",
    "# --------------------------\n",
    "nb_nodes, nb_edges = 7000, 10000\n",
    "graph = UndirectedGraph(nb_nodes)\n",
    "# Generate some random connections between nodes (avoiding self-loop):\n",
    "random_edges = np.random.randint(0, nb_nodes - 1, size=(nb_edges, 2))\n",
    "self_loops = np.argwhere(random_edges[:,0] == random_edges[:,1])\n",
    "random_edges = np.delete(random_edges, self_loops, axis=0)\n",
    "# Add connections to the graph:\n",
    "graph.insertEdges(random_edges)\n",
    "# Now, let's sample some random (signed) weights:\n",
    "random_signed_weights = np.random.uniform(-1., 1., size=graph.numberOfEdges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000,)\n"
     ]
    }
   ],
   "source": [
    "# And finally, we run GASP on the toy graph:\n",
    "# the output of the GASP function is an array of node labels, such that all nodes in the\n",
    "# same cluster are assigned to a distinct label.\n",
    "node_labels_gasp_clustering, runtime_gasp_graph = run_GASP(graph,\n",
    "                                      random_signed_weights,\n",
    "                                      linkage_criteria='average',\n",
    "                                      add_cannot_link_constraints=False,\n",
    "                                      verbose=False,\n",
    "                                      print_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}